{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessing the attitudes towards the proposed new ACMA powers to combat misinformation and disinformation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate prompt\n",
    "\n",
    "This function takes the submission and submission author (from doc name) as a\n",
    "parameter and returns the formatted prompt to be sent to the LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_formatted(submission_string: str, submission_author: str) -> str:    \n",
    "    # Read the first file and set a string variable\n",
    "    with open('prompt.txt', 'r') as file:\n",
    "        prompt = file.read()\n",
    "        \n",
    "    with open('prompt_issues.md', 'r') as file:\n",
    "        issues = file.read()\n",
    "\n",
    "    with open('prompt_guidance_note.md', 'r') as file:\n",
    "        guidance_note = file.read()\n",
    "\n",
    "    with open('prompt_fact_sheet.md', 'r') as file:\n",
    "        fact_sheet = file.read()\n",
    "\n",
    "    prompt = prompt.replace('|issues|', issues)\n",
    "    prompt = prompt.replace('|guidance_note|', guidance_note)\n",
    "    prompt = prompt.replace('|fact_sheet|', fact_sheet)\n",
    "\n",
    "    prompt += \"\\n\\n***************************************** SUBMISSION START *****************************************\\n\\n\"\n",
    "\n",
    "    prompt += f\"Submission from: {submission_author}\\n\\n\"\n",
    "    \n",
    "    prompt += submission_string\n",
    "\n",
    "    prompt += \"\\n\\n***************************************** SUBMISSION END *****************************************\\n\\n\"\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get AI response\n",
    "\n",
    "This function calls the AI model to elicit a response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started /Users/k/.cache/weaviate-embedded: process ID 15148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-05-07T18:09:48+10:00\"}\n",
      "{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-05-07T18:09:48+10:00\"}\n",
      "{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-05-07T18:09:48+10:00\"}\n",
      "{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-05-07T18:09:48+10:00\"}\n",
      "{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-05-07T18:09:48+10:00\"}\n",
      "{\"action\":\"restapi_management\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-05-07T18:09:48+10:00\"}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error setting up classes\n",
      "string indices must be integers, not 'str'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"level\":\"info\",\"msg\":\"Completed loading shard submission_ZLYAOU19n7NA in 10.686084ms\",\"time\":\"2024-05-07T18:09:49+10:00\"}\n",
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-05-07T18:09:49+10:00\",\"took\":4078667}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 131072 tokens. However, your messages resulted in 332816 tokens (332049 in the messages, 767 in the functions). Please reduce the length of the messages or functions.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n",
      "\n",
      "***\n",
      "\n",
      "Error processing file: 34751-anonymous.md\n",
      "'str' object does not support item assignment\n",
      "{'substantive_submission': True, 'responder_category': 'Individual', 'support': 'oppose', 'motivations': ['Freedom of speech', 'Democratic principles', 'Government overreach'], 'regulation': \"The submission opposes the form of regulation proposed by the Bill, arguing that it is not the government's role to dictate what constitutes misinformation and disinformation. The submitter believes that individuals are capable of assessing information themselves and that government intervention in this area could lead to undemocratic practices similar to those in less democratic countries.\", 'perceived_impact': 'The submitter perceives the impact of the proposed laws negatively, suggesting that they could infringe on individual freedoms and democratic principles. The submission implies that the laws could lead to government overreach and potentially suppress freedom of speech.', 'regulator_trust': 'No comment'}\n",
      "client initialized\n",
      "{'substantive_submission': True, 'responder_category': 'Civil Society', 'support': 'neutral', 'motivations': ['Freedom of speech', 'Human rights protection', 'Need for clarity'], 'regulation': \"The submission expresses concerns about the broad qualifiers and seemingly low thresholds within the Bill's provisions for establishing whether shared content is misinformation and/or disinformation, which could compromise freedom of speech. It suggests that guidance, clarification, and refinement of broad terms are essential to ensure clarity for digital service providers and the public regarding the activation of the ACMA's proposed new powers.\", 'perceived_impact': 'No comment', 'regulator_trust': \"The submission does not directly express trust or skepticism towards the ACMA's ability to impartially and effectively use the new powers. However, it emphasizes the need for a federal Human Rights Act to ensure that reforms do not infringe on internationally-recognized human rights, suggesting a broader concern for the protection of rights in the regulatory process.\"}\n",
      "{'substantive_submission': True, 'responder_category': 'Individual', 'support': 'oppose', 'motivations': ['Freedom of press', 'Unfair treatment', 'Media integrity'], 'regulation': 'The submission criticizes the bill for creating a complex web of reporting standards and misinformation reports that could harm the reputation of independent media organizations, journalists, and bloggers. It argues that the exemption for government-authorised publications creates an unlevel playing field, potentially leading to biased news coverage and financial benefits for government-approved journalists. The submission suggests that this selective treatment undermines the principles of a free and independent media, essential for a thriving democracy.', 'perceived_impact': 'The submitter perceives the bill as a direct attack on independent media organizations, journalists, and bloggers, potentially ruining their reputations through misinformation and disinformation reports. It suggests that the bill favors government-approved journalists, creating an unfair advantage and undermining media integrity. The submission argues that this approach stifles non-approved voices and threatens the integrity of independent journalism, which is crucial for a democratic society.', 'regulator_trust': 'No comment'}\n"
     ]
    }
   ],
   "source": [
    "from az_client import call_ai, get_vector\n",
    "from db.docs import DocumentManager\n",
    "from db.db_instance import DBClient\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "client = DBClient()\n",
    "db = DocumentManager()\n",
    "\n",
    "with open('function.json', 'r') as f:\n",
    "    function = json.load(f)\n",
    "\n",
    "def extract_name_from_filename(filename):\n",
    "    parts = filename.split('-')\n",
    "    name_parts = parts[1:]\n",
    "    name = ' '.join(name_parts).split('.')[0]\n",
    "    return name\n",
    "\n",
    "def add_to_json(data, filename):\n",
    "    if not os.path.isfile('./data/processed_data.json'):\n",
    "        with open('./data/processed_data.json', 'w') as f:\n",
    "            json.dump([], f)    \n",
    "    with open('./data/processed_data.json', 'r') as f:\n",
    "        previous_data = json.load(f)\n",
    "        previous_data.append({filename: data})    \n",
    "    with open('./data/processed_data.json', 'w') as f:\n",
    "        json.dump(previous_data, f)\n",
    "\n",
    "def process_files_in_directory(directory, completed_directory):\n",
    "    # Check if the 'completed' directory exists, if not, create it\n",
    "    if not os.path.exists(completed_directory):\n",
    "        os.makedirs(completed_directory)\n",
    "    for filename in os.listdir(directory)[:300]:\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isfile(filepath) and filename.endswith('.md'):\n",
    "            try:\n",
    "                with open(filepath, 'r') as file:\n",
    "                    submission = file.read()\n",
    "                sub_author = extract_name_from_filename(filename)\n",
    "                prompt = prompt_formatted(submission, sub_author)\n",
    "                response = call_ai(prompt, function)\n",
    "                \n",
    "                response[\"author\"] = sub_author\n",
    "                response[\"file_name\"] = filename.replace('.md', '')\n",
    "\n",
    "                vector = get_vector(submission)\n",
    "\n",
    "                db.new_doc(response, vector, True)\n",
    "                add_to_json(response, filename.split('-')[0])\n",
    "                # Move the processed file to the 'completed' directory\n",
    "                completed_filepath = os.path.join(completed_directory, filename)\n",
    "                shutil.move(filepath, completed_filepath)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file: {filename}\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "# Example usage\n",
    "directory = './data/files/converted'\n",
    "completed_directory = './data/files/completed'\n",
    "process_files_in_directory(directory, completed_directory)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
