{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 (still being implemented)\n",
    "\n",
    "This step processes each specific interest group. It is expected at this stage\n",
    "each individual submission will be correctly classified into one of the\n",
    "following categories:\n",
    "\n",
    "- News\n",
    "- Platform\n",
    "- Civil\n",
    "- Academic\n",
    "- Individual\n",
    "\n",
    "We are interested in the first four. Where AI has classified something into the\n",
    "first four that we had not in our original sweep, we would have checked that as\n",
    "the last part of step_1 and corrected the list in the files: `list.json`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from collections import Counter\n",
    "\n",
    "promt_file = 'prompt_no_guidance.txt'\n",
    "\n",
    "# Define the prompt for each individual request\n",
    "def prompt_formatted() -> str:    \n",
    "    # Read the first file and set a string variable\n",
    "    with open(promt_file, 'r') as file:\n",
    "        prompt = file.read()\n",
    "        \n",
    "    with open('prompt_issues.md', 'r') as file:\n",
    "        issues = file.read()\n",
    "\n",
    "    # with open('prompt_guidance_note.md', 'r') as file:\n",
    "    #     guidance_note = file.read()\n",
    "\n",
    "    with open('prompt_fact_sheet.md', 'r') as file:\n",
    "        fact_sheet = file.read()\n",
    "\n",
    "    prompt = prompt.replace('|issues|', issues)\n",
    "    # prompt = prompt.replace('|guidance_note|', guidance_note)\n",
    "    prompt = prompt.replace('|fact_sheet|', fact_sheet)    \n",
    "\n",
    "    return prompt\n",
    "\n",
    "def get_function(type: str):\n",
    "    if type == 'academic' or type == 'civil' or type == 'political' or type == 'government':\n",
    "        with open('function_civil_academic.json', 'r') as f:\n",
    "            function = json.load(f)\n",
    "        return function\n",
    "    if type == 'platform' or type == 'industry':\n",
    "        with open('function_digital.json', 'r') as f:\n",
    "            function = json.load(f)\n",
    "        return function\n",
    "    if type == 'news':\n",
    "        with open('function_news.json', 'r') as f:\n",
    "            function = json.load(f)\n",
    "        return function\n",
    "\n",
    "def get_file_path(doc_id, folder_path = './data/files'):    \n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.startswith(doc_id):\n",
    "            return os.path.join(folder_path, file_name)\n",
    "\n",
    "# Load original JSON list\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list_data = json.load(f)\n",
    "\n",
    "# This gets a list of just items of interest, filtering out individual submissions and those that were ignored\n",
    "to_process = [item for item in list_data[\"data\"] if item['group'] and item['group'] != 'individual']\n",
    "\n",
    "# Create step 2 directories\n",
    "os.makedirs('./data/step2', exist_ok=True)\n",
    "os.makedirs('./data/step2/toProcess', exist_ok=True)\n",
    "os.makedirs('./data/step2/output', exist_ok=True)\n",
    "\n",
    "file_counter = 0\n",
    "jsonl_file = f\"./data/step2/toProcess/jsonl_{file_counter}.jsonl\"\n",
    "\n",
    "# Count the number of each group\n",
    "group_values = [item['group'] for item in to_process]\n",
    "\n",
    "# Count occurrences of each group\n",
    "group_counts = Counter(group_values)\n",
    "\n",
    "# Convert to dictionary\n",
    "group_counts_dict = dict(group_counts)\n",
    "\n",
    "functions = {}\n",
    "\n",
    "for i in to_process:\n",
    "    try: \n",
    "        md_file_path = get_file_path(i.get(\"uniqueId\"))       \n",
    "        with open(md_file_path, 'r') as file:\n",
    "            submission = file.read()\n",
    "        sub_author = i[\"submitter\"]        \n",
    "        prompt = prompt_formatted()\n",
    "        submission_formatted = i[\"metadata\"][\"SUBMISSION_CONTENT\"]\n",
    "        function = get_function(i[\"group\"])\n",
    "        functions[i[\"group\"]] = function\n",
    "\n",
    "        ldata = { \"custom_id\": i[\"uniqueId\"], \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-2024-05-13\", \"messages\": [{\"role\": \"system\", \"content\": prompt}, {\"role\": \"user\", \"content\": submission_formatted}], \"max_tokens\": 4096, \"temperature\": 1e-9, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"top_p\": 0, \"tools\": [function], \"tool_choice\": { \"type\": \"function\", \"function\": { \"name\": \"submission_eval\" } }}}\n",
    "\n",
    "        if os.path.exists(jsonl_file) and os.path.getsize(jsonl_file) >= 85 * 1024 * 1024:\n",
    "            file_counter += 1\n",
    "            jsonl_file = f\"./data/step2/toProcess/jsonl_{file_counter}.jsonl\"\n",
    "                    \n",
    "        i[\"metadata\"][\"step_2\"] = {\"batch\": f'jsonl_{file_counter}.jsonl'}\n",
    "        \n",
    "        with open(jsonl_file, 'a') as f:\n",
    "            json.dump(ldata, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "\n",
    "local_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.now(local_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "list_data[\"metadata\"][\"step_2\"] = {    \n",
    "    \"jsonl_batch_creation\": {\n",
    "            \"timestamp\": current_time,\n",
    "            \"type_breakdown\": group_counts_dict,            \n",
    "        },\n",
    "    \"ai_parameters\" : { \n",
    "        \"custom_id\": \"SUBMISSION_ID\", \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-2024-05-13\", \"messages\": [{\"role\": \"system\", \"content\": prompt},{\"role\": \"user\", \"content\": \"SUBMISSION_CONTENT\"}], \"max_tokens\": 4096, \"temperature\": 1e-9, \"frequency_penalty\": 0, \"presence_penalty\": 0, \"top_p\": 0, \"tools\": \"AS_PER_GROUP_FN\", \"tool_choice\": { \"type\": \"function\", \"function\": { \"name\": \"submission_eval\" } }}},\n",
    "    \"functions\": functions,\n",
    "        }\n",
    "\n",
    "with open('./data/step1/list.json', 'w') as f:\n",
    "    json.dump(list_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We now have a folder with all the prepared files for OpenAI batch calls\n",
    "\n",
    "We will upload each of these files to OpenAI and then trigger batch processing\n",
    "of each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'), max_retries=3)\n",
    "\n",
    "jsonl_dir = './data/step2/toProcess'\n",
    "\n",
    "jsonl_files = [f for f in os.listdir(jsonl_dir) if os.path.isfile(os.path.join(jsonl_dir, f)) and f.endswith('.jsonl')]\n",
    "\n",
    "file_ids = []\n",
    "\n",
    "for file in jsonl_files:\n",
    "    file_object = client.files.create(\n",
    "        file=open(f\"{jsonl_dir}/{file}\", \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    file_ids.append(file_object.id)\n",
    "\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list = json.load(f)\n",
    "\n",
    "local_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.now(local_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "list[\"metadata\"][\"step_2\"][\"file_upload\"] = {\n",
    "            \"timestamp\": current_time,\n",
    "            \"file_ids\": file_ids,            \n",
    "        }\n",
    "\n",
    "with open('./data/step1/list.json', 'w') as f:\n",
    "    json.dump(list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_sDcEEYbyii64rVYSXPYiRUP6']\n"
     ]
    }
   ],
   "source": [
    "# CELL 3\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'), max_retries=3)\n",
    "\n",
    "# We have now uploaded all the files and have their IDs, lets create a batch job for each\n",
    "batch_ids = []\n",
    "\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list = json.load(f)\n",
    "\n",
    "file_ids = list[\"metadata\"][\"step_2\"][\"file_upload\"][\"file_ids\"]\n",
    "\n",
    "for file_id in file_ids:\n",
    "    job = client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "          )\n",
    "    batch_ids.append(job.id)\n",
    "\n",
    "print(batch_ids)\n",
    "\n",
    "local_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.now(local_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"] = {\n",
    "            \"timestamp\": current_time,\n",
    "            \"batch_ids\": batch_ids,\n",
    "        }\n",
    "\n",
    "with open('./data/step1/list.json', 'w') as f:\n",
    "    json.dump(list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The batch processes should now be underway, they will take up to 24hrs\n",
    "\n",
    "We can run the following cell to check on process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_sDcEEYbyii64rVYSXPYiRUP6 completed BatchRequestCounts(completed=123, failed=0, total=123)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'),max_retries=3)\n",
    "\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list = json.load(f)\n",
    "\n",
    "desired_batch_ids = list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"batch_ids\"]\n",
    "\n",
    "batch_jobs = client.batches.list()\n",
    "\n",
    "for batch in batch_jobs.data:\n",
    "    if batch.id in desired_batch_ids:\n",
    "        print(batch.id, batch.status, batch.request_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once processing is done, we can download the completed files\n",
    "\n",
    "Files are saved here: `./data/step2/output`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'),max_retries=3)\n",
    "\n",
    "batch_jobs = client.batches.list()\n",
    "\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list = json.load(f)\n",
    "\n",
    "# we only want to download the batch jobs that were set up in cell 11\n",
    "desired_batch_ids = list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"batch_ids\"]\n",
    "\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "created_time = None\n",
    "completion_time = None\n",
    "\n",
    "success_files = []\n",
    "err_files = []\n",
    "\n",
    "for batch in batch_jobs.data:\n",
    "    if batch.id in desired_batch_ids:\n",
    "        # Gets the first created batch time\n",
    "        if not created_time or batch.created_at < created_time:\n",
    "            created_time = batch.created_at\n",
    "        # Gets the lasted completed batch time\n",
    "        if not completion_time or batch.completed_at > completion_time:\n",
    "            completion_time = batch.completed_at\n",
    "        if batch.output_file_id:\n",
    "            success_count += batch.request_counts.total - batch.request_counts.failed\n",
    "            output_file = batch.output_file_id\n",
    "            content = client.files.content(output_file)\n",
    "            jsonl_file_path = f'./data/step2/output/{output_file}.jsonl'\n",
    "            content.write_to_file(jsonl_file_path)\n",
    "            success_files.append(jsonl_file_path)\n",
    "        # Handle error files\n",
    "        if batch.error_file_id:\n",
    "            error_count += batch.request_counts.failed\n",
    "            err_file = batch.error_file_id\n",
    "            err_content = client.files.content(err_file)\n",
    "            err_jsonl_file_path = f'./data/step2/output/err_{err_file}.jsonl'\n",
    "            err_content.write_to_file(err_jsonl_file_path)\n",
    "            err_files.append(err_jsonl_file_path)\n",
    "\n",
    "local_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.now(local_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "time_difference = completion_time - created_time\n",
    "\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"download_timestamp\"] = current_time\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"completetion_duration_seconds\"] = time_difference\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"success\"] = success_count\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"errors\"] = error_count\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"success_files\"] = success_files\n",
    "list[\"metadata\"][\"step_2\"][\"batch_creation\"][\"error_files\"] = err_files\n",
    "\n",
    "with open('./data/step1/list.json', 'w') as f:\n",
    "    json.dump(list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process AI responses and save data\n",
    "\n",
    "Now we have all the AI responses, we need to process and save the results. This\n",
    "will update the json file from step 2, and also export the responses as an Excel\n",
    "file for review. The Excel file will be located: `./data/step2/review2/xlsx`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'),max_retries=3)\n",
    "\n",
    "# Parses the JSON from a function call, if there is an error in JSON parsing, recalls the LLM with the fix json function to get a valid json response.\n",
    "def parse_JSON(json_str: str) -> dict:        \n",
    "    try: \n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:              \n",
    "        messages = [\n",
    "      {\n",
    "        'role': 'system',\n",
    "        'content':\n",
    "          'Assistant is a large language model designed to fix and return correct JSON objects.',\n",
    "      },\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': f'ORIGINAL ERROR CONTAINING JSON OBJECT:\\n\\n{json_str}\\n\\nERROR MESSAGE: {e}',\n",
    "      },\n",
    "    ]\n",
    "        \n",
    "        tool_choices = [{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'fix_object',\n",
    "        'description':\n",
    "          'You will be given an incorrectly formed JSON Object and a error message. You must fix the incorrect JSON Object and return the valid JSON object.',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'fixedJSON': {\n",
    "              'type': 'string',\n",
    "              'description': 'The reformated and error free JSON object. Return the JSON object only!',\n",
    "            },\n",
    "          },\n",
    "          'required': ['fixedJSON'],\n",
    "        },\n",
    "      },\n",
    "    }]                \n",
    "        response = client.chat.completions.create(\n",
    "                    model='gpt-4o-2024-05-13',\n",
    "                    messages=messages,                    \n",
    "                    max_tokens=4096,\n",
    "                    temperature=0,\n",
    "                    tools=tool_choices,\n",
    "                    tool_choice={ 'type': 'function', 'function': { 'name': 'fix_object' } },        \n",
    "                )        \n",
    "                \n",
    "        second_test_json = response.choices[0].message.tool_calls[0].function.arguments \n",
    "                  \n",
    "        to_return = json.loads(second_test_json)\n",
    "        return json.loads(to_return['fixedJSON'])\n",
    "\n",
    "output_folder = './data/step2/output'\n",
    "\n",
    "jsonl_files = [f for f in os.listdir(output_folder) if os.path.isfile(os.path.join(output_folder, f)) and f.endswith('.jsonl')]\n",
    "\n",
    "# Load original JSON list\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list_data = json.load(f)\n",
    "\n",
    "def get_correct_category(AI_category):\n",
    "    AI_category = AI_category.lower()    \n",
    "    if AI_category == 'digital platform':\n",
    "        return 'platform'\n",
    "    if AI_category == 'civil society':\n",
    "        return 'civil'\n",
    "    return AI_category\n",
    "\n",
    "prompt_tokens = 0\n",
    "completion_tokens = 0\n",
    "total_tokens = 0\n",
    "\n",
    "# Load the JSONL files\n",
    "for file in jsonl_files:    \n",
    "    with open(f\"{output_folder}/{file}\", \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)            \n",
    "            item_key = item['custom_id']            \n",
    "            # grab the matching item in our list            \n",
    "            list_item = next((x for x in list_data[\"data\"] if x['uniqueId'] == item_key), None)\n",
    "            if list_item:\n",
    "              if item[\"response\"][\"status_code\"] != 200:\n",
    "                list_item[\"step_2\"] = None\n",
    "                list_item[\"metadata\"][\"step_2\"][\"error\"] = item[\"response\"]\n",
    "                continue                \n",
    "              json_res = parse_JSON(item['response']['body']['choices'][0]['message']['tool_calls'][0]['function']['arguments'])\n",
    "              list_item[\"step_2\"] = json_res\n",
    "              list_item[\"metadata\"][\"step_2\"][\"system_fingerprint\"] = item['response']['body']['system_fingerprint']\n",
    "              list_item[\"metadata\"][\"step_2\"][\"batch_id\"] = item['id']\n",
    "              prompt_tokens += item['response']['body'][\"usage\"][\"prompt_tokens\"]\n",
    "              completion_tokens += item['response']['body'][\"usage\"][\"completion_tokens\"]\n",
    "              total_tokens += item['response']['body'][\"usage\"][\"total_tokens\"]\n",
    "\n",
    "local_timezone = pytz.timezone('Australia/Sydney')\n",
    "current_time = datetime.now(local_timezone).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "\n",
    "list_data[\"metadata\"][\"step_2\"][\"batch_processed\"] = {\"timestamp\": current_time}\n",
    "list_data[\"metadata\"][\"step_2\"][\"usage\"] = {\"prompt_tokens\": prompt_tokens, \"completion_tokens\": completion_tokens, \"total_tokens\": total_tokens}\n",
    "\n",
    "# Save the updated list back to the json file\n",
    "with open('./data/step1/list.json', 'w') as f:\n",
    "    json.dump(list_data, f)\n",
    "\n",
    "# Export the list to an Excel file for review\n",
    "# Convert JSON to DataFrame\n",
    "df = pd.json_normalize(list_data[\"data\"])\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel('./data/step2/step2.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
