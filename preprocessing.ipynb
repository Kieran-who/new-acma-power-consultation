{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1:\n",
    "\n",
    "In this step we carry out the following:\n",
    "\n",
    "1. We load the spreadsheet from Sharepoint which includes the list of\n",
    "   submissions, the human defined categories for submitters of interest and any\n",
    "   furhter annotations such as whether we are removing submissions from\n",
    "   analysis. We format this data into a json file, saved in\n",
    "   `./data/step1/list.json`. This JSON file allows for easier manipulation and\n",
    "   handling.\n",
    "2. Using the JSON file from step 1, we create a number of jsonl files that are\n",
    "   in the correct format for processing by OpenAI's batch API. We create\n",
    "   multiple jsonl files as each has to be less than 100mb in size.\n",
    "3. We upload the jsonl files, and trigger the batch processing of them. This can\n",
    "   take upwards of 24 hours.\n",
    "4. Once processing is complete, we download the completed responses for each\n",
    "   request, and update the json file from step 1 to include the AI returned\n",
    "   data. We also export this data in a spreadsheet for review\n",
    "   (`./data/step1/review1.xlsx`)\n",
    "\n",
    "With this, we can check if the AI has catagorised any of the unlabeled\n",
    "submissions into the categories of interest that we may have missed. Once we are\n",
    "settled on the categories, we can move onto `Step 2` which involves asking the\n",
    "AI the specific questions for each category.\n",
    "\n",
    "This step asks the AI to evaluate each submission by responding to the following\n",
    "questions:\n",
    "\n",
    "- **substantive_submission**: \"Does the submission provide a substantive\n",
    "  response to the consultation (True or False)? Substantive submissions are\n",
    "  those that provide a detailed or well reasoned response to the consultation.\n",
    "  Screenshots of memes or other pre-existing content are not considered\n",
    "  substantive. Submissions relying on conspiracy theories are not considered\n",
    "  substantive. A submission expressing purely personal opinio, without any\n",
    "  supporting argument, is not considered substantive. Consider the supplementary\n",
    "  materials and determine if the submission answers substantively answers the\n",
    "  issues, concerns and questions raised in the consultation.\n",
    "- **responder_category**: \"One aspect of the research is looking how different\n",
    "  categories of responders respond to the consultation. Based on the response\n",
    "  (especially the name of the responder - e.g. if it is a company or group),\n",
    "  please select the category that best describes the responder. Options are: 1.\n",
    "  Individual 2. Political (e.g. politician or political part) 3. Digital\n",
    "  Platform (e.g. Meta, Microsoft, Google, etc.) 4. Civil Society (e.g. NGO,\n",
    "  advocacy group, etc.) 5. Academic 6. News (e.g. a news company such as News\n",
    "  Corp, ABC or Nine News, or a industry association representing news\n",
    "  organisations such as Australian Press Council or Commerical Radio Australia\n",
    "  or FreeTV) 7. Government (e.g. government agencies such as Victorian Electoral\n",
    "  Commission or Australian Human Rights Commission) 8. Industry: An industry\n",
    "  body that does not neatly fit within the predefined categories (e.g. while\n",
    "  Commerical Radio Australia represents news broadcasters and as such fits\n",
    "  within News, an industry body such as Communications Alliance, which\n",
    "  represents communications providers such as a telcos and broadband companies\n",
    "  would fit here) 9. Other (please specify). Only return the category that best\n",
    "  describes the responder. E.g. for a submission from the UTS Centre for Media\n",
    "  Transition, you would return: 'Academic'.\n",
    "- **support**: \"Overall, considering the whole of the submission, does the\n",
    "  submission support, oppose, or have a neutral stance towards the proposed\n",
    "  laws? Make sure you truly understand the submission's position taking into\n",
    "  account the whole document. Look for express statement's expressing support or\n",
    "  opposition. If no express statements are present, weight up the arguments\n",
    "  against and arguments in favour of the Bill and specific aspects of the\n",
    "  proposed changes. Some confusion may arise where the submission states it is\n",
    "  supporting another submission â€“ this does not mean the submission is in\n",
    "  support of the proposed changes. In these circumstances, if you are unsure\n",
    "  (i.e. the submission is not clear and you do not have access to the submission\n",
    "  being referred to), respond with 'unsure'. (return only one of the following\n",
    "  options: 'support', 'oppose', 'neutral', 'unsure').\n",
    "- **motivations**: \"Number the top 3 motivations or concerns underpinning the\n",
    "  submission's view point. Keep each motivation general, short and brief (under\n",
    "  5 words). If only one or two key motivations, return only these one or two.\n",
    "- **changes**: \"Does this submission provide suggestions on what changes need to\n",
    "  be made in the Bill? If so, please list each suggested change, with the most\n",
    "  important changes first. You do not need to describe each change in detail,\n",
    "  just give a onelight statement of what the submitter requests to be changed.\n",
    "  If no comment on this aspect, return 'No comment'.\n",
    "- **regulation**: \"Does this submission make any comment on the form of\n",
    "  regulation provided by the Bill. For example, does the submission comment on\n",
    "  the practicality, feasibility or merits of self-regulation, codes of practice,\n",
    "  industry standards or legislation? If co-regulation or self-regulation is\n",
    "  mentioned highlight this. This question is only interested in the submission's\n",
    "  view on the FORM OF REGULATION and NOT whether or not the issue should be\n",
    "  regulated or what the impacts of regulation may be. Do not summarise the\n",
    "  impacts the submission may believe regulation in general will have, WE ARE\n",
    "  ONLY interested in specific comments as to the form of regulation (e.g.\n",
    "  self-regulation, quasi-regulation, co-regulation, industry codes of practice,\n",
    "  industry-regulator collaboration, industry standards, Direct government\n",
    "  regulation, etc.). If the submission makes explicit comments as to the form of\n",
    "  regulation, please provide a brief summary of the comment, and the reasoning\n",
    "  behind their belief. If no comment on this aspect, return 'No comment'.\n",
    "- **perceived_societal_impact**: \"How does the submitter perceive the impact of\n",
    "  the proposed laws on combating misinformation and disinformation and the\n",
    "  broader digital ecosystem, including social media platforms, content creators,\n",
    "  and the general public? Restrict your summary on this point purely to what\n",
    "  impacts the submission has highlighted relating to combating misinformation\n",
    "  and disinformation and the broader digital ecosystem, including social media\n",
    "  platforms, content creators, and the general public. Do not include comments\n",
    "  on feasibility or any other aspects covered by other questions. If no comment\n",
    "  on this aspect, return 'No comment'.\n",
    "- **regulator_trust**: \"Does the submission express trust or skepticism towards\n",
    "  the Australian Media and Communications Authority (ACMA)'s ability to\n",
    "  impartially and effectively use the new powers? Are there any suggestions for\n",
    "  ensuring accountability and oversight? Please only highlight express\n",
    "  statements as to the ability of the ACMA to impartially and effectively use\n",
    "  the new powers, or any suggestions for ensuring accountability and oversight\n",
    "  of ACMA exercising its power. If no comment on this aspect, return 'No\n",
    "  comment'.\n",
    "- **definitions**: \"What does the submitter think about the definitions of\n",
    "  misinformation, disinformation and serious harm? Only consider comments on the\n",
    "  definitions of 'misinformation', 'disinformation' and 'serious harm'. If the\n",
    "  submitter makes no comment on the definitions of these specific terms, return\n",
    "  'No comment'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading spreadsheet\n",
    "\n",
    "[The spreadsheet](https://studentutsedu.sharepoint.com/:x:/r/sites/CentreforMediaTransition76/_layouts/15/doc2.aspx?sourcedoc=%7B26015E46-DC17-46F8-85CB-8FF7601BB93E%7D&file=List%20of%20all%20submissions.xlsx&action=default&mobileredirect=true&DefaultItemOpen=1&ct=1715733887026&wdOrigin=OFFICECOM-WEB.START.REC&cid=c80abce9-d7d3-419b-8b78-2504ae4ce71a&wdPreviousSessionSrc=HarmonyWeb&wdPreviousSession=a8d0354e-a231-454b-a8a5-18124a5f1983)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the Excel spreadsheet into a pandas DataFrame\n",
    "df = pd.read_excel('./data/step1/list.xlsx')\n",
    "\n",
    "# Convert the DataFrame to a list of dictionaries\n",
    "data = df.to_dict(orient='records')\n",
    "\n",
    "def extract_name_from_filename(filename):\n",
    "    parts = filename.split('-')\n",
    "    name_parts = parts[1:]\n",
    "    name = ' '.join(name_parts).split('.')[0]\n",
    "    if name.find('anonymous') != -1:\n",
    "        name = 'anonymous'\n",
    "    return name.lower()\n",
    "\n",
    "formatted_data = []\n",
    "# Convert empty cells in 'Group', 'Comments', and 'Removed (Y)' columns to None\n",
    "for row in data:\n",
    "    if pd.isnull(row['Group']):\n",
    "        row['Group'] = None\n",
    "    if pd.isnull(row['Comments']):\n",
    "        row['Comments'] = None\n",
    "    if pd.isnull(row['Removed (Y)']):\n",
    "        row['Removed (Y)'] = None\n",
    "\n",
    "    file_name = row['doc'].replace('acma2023-', '').replace('.pdf', '')\n",
    "    \n",
    "    formatted_row = {\n",
    "        'uniqueId': row['UniqueID'],\n",
    "        'group': row['Group'],\n",
    "        'submitter': extract_name_from_filename(file_name),\n",
    "        'doc': file_name,\n",
    "        \"metadata\": {\n",
    "            \"groupDefinedBy\": \"human\" if row['Group'] else \"AI\",\n",
    "            \"removed\": row['Removed (Y)'],\n",
    "            \"comments\": row['Comments']            \n",
    "        }\n",
    "    }\n",
    "    formatted_data.append(formatted_row)\n",
    "\n",
    "# Save the data as a JSON file if it doesn't exist\n",
    "json_file = './data/step1/list.json'\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(formatted_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. We now have a JSON file of objects with key value pairs in the below form. We now process this to jsonl form for batch processing\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"group\": \"string | null\",\n",
    "  \"submitter\": \"string\",\n",
    "  \"doc\": \"string\",\n",
    "  \"uniqueId\": \"string\",\n",
    "  \"metadata\": {\n",
    "    \"groupDefinedBy\": \"human or AI\",\n",
    "    \"removed\": \"string | null\",\n",
    "    \"comments\": \"string | null\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "We ignore in this step any submissions we flag as removed.\n",
    "\n",
    "jsonl files saved to `./data/step1/toProcess`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the prompt for each individual request\n",
    "def prompt_formatted(submission_string: str, submission_author: str) -> str:    \n",
    "    # Read the first file and set a string variable\n",
    "    with open('prompt.txt', 'r') as file:\n",
    "        prompt = file.read()\n",
    "        \n",
    "    with open('prompt_issues.md', 'r') as file:\n",
    "        issues = file.read()\n",
    "\n",
    "    with open('prompt_guidance_note.md', 'r') as file:\n",
    "        guidance_note = file.read()\n",
    "\n",
    "    with open('prompt_fact_sheet.md', 'r') as file:\n",
    "        fact_sheet = file.read()\n",
    "\n",
    "    prompt = prompt.replace('|issues|', issues)\n",
    "    # prompt = prompt.replace('|guidance_note|', guidance_note)\n",
    "    prompt = prompt.replace('|guidance_note|', '')\n",
    "    prompt = prompt.replace('|fact_sheet|', fact_sheet)\n",
    "\n",
    "    prompt += \"\\n\\n***************************************** SUBMISSION START *****************************************\\n\\n\"\n",
    "\n",
    "    prompt += f\"Submission from: {submission_author}\\n\\n\"\n",
    "    \n",
    "    prompt += submission_string\n",
    "\n",
    "    prompt += \"\\n\\n***************************************** SUBMISSION END *****************************************\\n\\n\"\n",
    "\n",
    "    return prompt    \n",
    "\n",
    "def get_function():\n",
    "    with open('function.json', 'r') as f:\n",
    "        function = json.load(f)\n",
    "    return function\n",
    "\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list = json.load(f)\n",
    "\n",
    "md_file_location = './data/files/md_files'\n",
    "\n",
    "file_counter = 0\n",
    "jsonl_file = f\"./data/step1/toProcess/jsonl_{file_counter}.jsonl\"\n",
    "\n",
    "counter = 0\n",
    "# This loop takes each submission and adds it to the jsonl file in a format that can be used by the OpenAI API\n",
    "for i in list:\n",
    "    if counter >= 200:\n",
    "        break\n",
    "    if i[\"metadata\"][\"removed\"] == \"Y\":\n",
    "        continue\n",
    "    try:\n",
    "        md_file_path = f\"{md_file_location}/{i[\"doc\"]}/{i[\"doc\"]}.md\"        \n",
    "        with open(md_file_path, 'r') as file:\n",
    "            submission = file.read()\n",
    "        sub_author = i[\"submitter\"]\n",
    "        prompt = prompt_formatted(submission, sub_author)\n",
    "        function = get_function()\n",
    "        ldata = {\"custom_id\": i[\"uniqueId\"], \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": {\"model\": \"gpt-4o-2024-05-13\", \"messages\": [{\"role\": \"user\", \"content\": prompt}],\"max_tokens\": 4096,\"temperature\": 0, \"tools\":[function], \"tool_choice\":{ 'type': 'function', 'function': { 'name': 'submission_eval' } }}}        \n",
    "        \n",
    "        if os.path.exists(jsonl_file) and os.path.getsize(jsonl_file) >= 85 * 1024 * 1024:  # 90MB\n",
    "            file_counter += 1\n",
    "            jsonl_file = f\"./data/step1/toProcess/jsonl_{file_counter}.jsonl\"\n",
    "        \n",
    "        with open(jsonl_file, 'a') as f:\n",
    "            json.dump(ldata, f)\n",
    "            f.write('\\n')\n",
    "        counter += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. We now have a folder with all the prepared files for OpenAI batch calls\n",
    "\n",
    "We will upload each of these files to OpenAI and then trigger batch processing\n",
    "of each.\n",
    "\n",
    "**MAKE SURE TO RECORD BATCH IDs CREATED IN THIS STEP SO WE KNOW WHICH FILES TO\n",
    "EVENTUALLY DOWNLOAD**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'), max_retries=3)\n",
    "\n",
    "jsonl_dir = './data/step1/toProcess'\n",
    "\n",
    "jsonl_files = [f for f in os.listdir(jsonl_dir) if os.path.isfile(os.path.join(jsonl_dir, f)) and f.endswith('.jsonl')]\n",
    "\n",
    "file_ids = []\n",
    "\n",
    "for file in jsonl_files:\n",
    "    file_object = client.files.create(\n",
    "        file=open(f\"{jsonl_dir}/{file}\", \"rb\"),\n",
    "        purpose=\"batch\"\n",
    "    )\n",
    "    file_ids.append(file_object.id)\n",
    "\n",
    "# We have now uploaded all the files and have their IDs, lets create a batch job for each\n",
    "batch_ids = []\n",
    "\n",
    "for file_id in file_ids:\n",
    "    job = client.batches.create(\n",
    "            input_file_id=file_id,\n",
    "            endpoint=\"/v1/chat/completions\",\n",
    "            completion_window=\"24h\"\n",
    "          )\n",
    "    \n",
    "    batch_ids.append(job.id)\n",
    "\n",
    "print('Record the following and make sure to add to `desired_batch_ids` in the following cells!')\n",
    "print(batch_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The batch processes should now be underway, they will take up to 24hrs\n",
    "\n",
    "We can run the following cell to check on process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'),max_retries=3)\n",
    "\n",
    "batch_jobs = client.batches.list()\n",
    "\n",
    "desired_batch_ids = ['batch_vdZSGRcPyfdMH8T0UCfssPpw']\n",
    "\n",
    "for batch in batch_jobs.data:\n",
    "    if batch.id in desired_batch_ids:\n",
    "        print(batch.id, batch.status, batch.request_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Once processing is done, we can download the completed files\n",
    "\n",
    "Files are saved here: `./data/step1/output`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_KEY'),max_retries=3)\n",
    "\n",
    "batch_jobs = client.batches.list()\n",
    "\n",
    "# we only want to download the batch jobs that were set up in cell 11\n",
    "desired_batch_ids = ['batch_vdZSGRcPyfdMH8T0UCfssPpw']\n",
    "\n",
    "for batch in batch_jobs.data:\n",
    "    if batch.id in desired_batch_ids:        \n",
    "        output_file = batch.output_file_id\n",
    "        content = client.files.content(output_file)    \n",
    "\n",
    "        jsonl_file_path = f'./data/step1/output/{output_file}.jsonl'\n",
    "        content.write_to_file(jsonl_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process AI responses and save data\n",
    "\n",
    "Now we have all the AI responses, we need to process and save the results. This\n",
    "will update the json file from step 2, and also export the responses as an Excel\n",
    "file for review. The Excel file will be located: `./data/step1/review1/xlsx`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from config import AZURE_OPENAI_KEY, AZURE_OPENAI_BASE_URL\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "azure_client = AzureOpenAI(\n",
    "    api_key=AZURE_OPENAI_KEY,\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=AZURE_OPENAI_BASE_URL\n",
    ")\n",
    "\n",
    "# Parses the JSON from a function call, if there is an error in JSON parsing, recalls the LLM with the fix json function to get a valid json response.\n",
    "def parse_JSON(json_str: str) -> dict:        \n",
    "    try: \n",
    "        return json.loads(json_str)\n",
    "    except Exception as e:              \n",
    "        messages = [\n",
    "      {\n",
    "        'role': 'system',\n",
    "        'content':\n",
    "          'Assistant is a large language model designed to fix and return correct JSON objects.',\n",
    "      },\n",
    "      {\n",
    "        'role': 'user',\n",
    "        'content': f'ORIGINAL ERROR CONTAINING JSON OBJECT:\\n\\n{json_str}\\n\\nERROR MESSAGE: {e}',\n",
    "      },\n",
    "    ]\n",
    "        \n",
    "        tool_choices = [{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'fix_object',\n",
    "        'description':\n",
    "          'You will be given an incorrectly formed JSON Object and a error message. You must fix the incorrect JSON Object and return the valid JSON object.',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'fixedJSON': {\n",
    "              'type': 'string',\n",
    "              'description': 'The reformated and error free JSON object. Return the JSON object only!',\n",
    "            },\n",
    "          },\n",
    "          'required': ['fixedJSON'],\n",
    "        },\n",
    "      },\n",
    "    }]                \n",
    "        response = azure_client.chat.completions.create(\n",
    "                    model='gpt-4',\n",
    "                    messages=messages,                    \n",
    "                    max_tokens=4096,\n",
    "                    temperature=0,\n",
    "                    tools=tool_choices,\n",
    "                    tool_choice={ 'type': 'function', 'function': { 'name': 'fix_object' } },        \n",
    "                )        \n",
    "                \n",
    "        second_test_json = response.choices[0].message.tool_calls[0].function.arguments \n",
    "                  \n",
    "        to_return = json.loads(second_test_json)\n",
    "        return json.loads(to_return['fixedJSON'])\n",
    "\n",
    "output_folder = './data/step1/output'\n",
    "\n",
    "jsonl_files = [f for f in os.listdir(output_folder) if os.path.isfile(os.path.join(output_folder, f)) and f.endswith('.jsonl')]\n",
    "\n",
    "# Load original JSON list\n",
    "with open('./data/step1/list.json', 'r') as f:\n",
    "    list_data = json.load(f)\n",
    "\n",
    "# Load the JSONL files\n",
    "for file in jsonl_files:\n",
    "    with open(f\"{output_folder}/{file}\", \"r\") as f:\n",
    "        for line in f:\n",
    "            item = json.loads(line)            \n",
    "            item_key = item['custom_id']            \n",
    "            json_res = parse_JSON(item['response']['body']['choices'][0]['message']['tool_calls'][0]['function']['arguments'])\n",
    "            # grab the matching item in our list\n",
    "            list_item = next((x for x in list_data if x['uniqueId'] == item_key), None)\n",
    "            if list_item:\n",
    "              if list_item['group'] == None:\n",
    "                list_item['group'] = json_res['responder_category'].lower()\n",
    "                list_item['metadata']['groupDefinedBy'] = 'AI'\n",
    "              list_item['metadata']['openAI_system_fingerprint'] = item['response']['body']['system_fingerprint']\n",
    "              list_item['AI_response_general'] = json_res\n",
    "\n",
    "# Save the updated list back to the json file\n",
    "with open('./data/step1/list.json', 'w') as f:\n",
    "    json.dump(list_data, f)\n",
    "\n",
    "# Export the list to an Excel file for review\n",
    "# Convert JSON to DataFrame\n",
    "df = pd.json_normalize(list_data)\n",
    "\n",
    "# Save DataFrame to Excel\n",
    "df.to_excel('./data/step1/review1.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
